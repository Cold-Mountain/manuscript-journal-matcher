# Manuscript Journal Matcher

<div align="center">

![Version](https://img.shields.io/badge/version-2.0-blue.svg)
![Status](https://img.shields.io/badge/status-production%20ready-green.svg)
![Python](https://img.shields.io/badge/python-3.8%2B-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

**ğŸ¯ Find the perfect journal for your research manuscript using AI-powered semantic matching**

[Quick Start](#quick-start) â€¢ [Features](#features) â€¢ [Documentation](#documentation) â€¢ [Demo](#demo) â€¢ [Contributing](#contributing)

</div>

---

## ğŸŒŸ Overview

The Manuscript Journal Matcher is an **AI-powered research tool** that helps academics and researchers find the most suitable journals for their manuscripts. Using advanced natural language processing and semantic similarity, it analyzes your research content and matches it against a comprehensive database of **7,600+ medical journals**.

### âœ¨ Why Use This Tool?

- **ğŸ¯ Accurate Matching**: Semantic analysis goes beyond keyword matching
- **ğŸ“Š Quality Metrics**: Journal rankings, impact factors, and quartile information
- **ğŸ’° Cost Transparency**: Article Processing Charges (APC) and open access data
- **âš¡ Fast Results**: Get recommendations in seconds, not hours
- **ğŸ”’ Privacy First**: Your manuscript content is never stored or shared

### ğŸ† Current Status

**Version**: 2.0 (Production Ready)  
**Database**: 7,648 medical journals (Medicine Journal Rankings 2024)  
**Last Updated**: July 29, 2025

## Project Overview

The Manuscript Journal Matcher is a fully functional web-based application that allows researchers to upload their manuscript (PDF or DOCX) and receive ranked suggestions of academic journals based on semantic similarity. The system extracts key metadata (title, abstract) from manuscripts and matches them to journals using advanced NLP embeddings and vector similarity search with comprehensive quality metrics.

## âœ¨ Features

### ğŸš€ Core Capabilities
- **ğŸ“„ Multi-Format Support**: Upload PDF or DOCX manuscripts
- **ğŸ¤– Smart Extraction**: Automatic title and abstract detection
- **ğŸ§  AI-Powered Matching**: Advanced BERT-based semantic similarity (384D embeddings)
- **ğŸ“Š Comprehensive Database**: 7,648 medical journals with complete metadata
- **âš¡ Lightning Fast**: Get results in <0.1 seconds

### ğŸ“ˆ Quality & Metrics  
- **ğŸ† Journal Rankings**: Scimago Journal Rankings with quartile classification (Q1-Q4)
- **ğŸ“Š Impact Metrics**: H-index, citation counts, and impact factors
- **ğŸ” Advanced Filtering**: Filter by quality, publisher, country, and subject area
- **ğŸ’° Cost Information**: Article Processing Charges (APC) and open access status
- **ğŸŒ Global Coverage**: Journals from 104+ countries and 2,000+ publishers

### ğŸ”’ Privacy & Performance
- **ğŸ›¡ï¸ Privacy First**: No manuscript content stored or transmitted externally
- **âš¡ High Performance**: Optimized for speed and memory efficiency
- **ğŸ¯ Proven Accuracy**: Validated against real-world publishing data
- **ğŸ“± User-Friendly**: Clean, intuitive web interface built with Streamlit

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8 or higher
- 4GB+ RAM recommended
- Internet connection for initial setup

### Installation
```bash
# Clone the repository
git clone https://github.com/Cold-Mountain/manuscript-journal-matcher.git
cd manuscript-journal-matcher

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Launch the application
streamlit run src/main.py
```

### First Use
1. ğŸ“ **Upload** your manuscript (PDF or DOCX format)
2. âš™ï¸ **Configure** search parameters (number of results, quality filters)
3. ğŸ” **Search** and get instant journal recommendations
4. ğŸ“Š **Review** results with quality metrics and cost information
5. ğŸ“‹ **Export** your results for further analysis

> **Need help?** Check out our [detailed setup guide](docs/user/installation-guide.md) or [troubleshooting guide](docs/user/troubleshooting.md).

## ğŸ”„ How It Works

```mermaid
graph LR
    A[ğŸ“„ Upload Manuscript] --> B[ğŸ” Extract Content]
    B --> C[ğŸ§  Generate Embeddings]
    C --> D[ğŸ” Semantic Search]
    D --> E[ğŸ† Rank & Filter]
    E --> F[ğŸ“Š Display Results]
```

1. **ğŸ“„ Document Processing**: Intelligent extraction of title, abstract, and metadata
2. **ğŸ§  AI Analysis**: Convert text to 384-dimensional semantic vectors using BERT
3. **ğŸ” Similarity Search**: FAISS-powered search through 7,600+ journal embeddings  
4. **ğŸ† Smart Ranking**: Combine semantic similarity with journal quality metrics
5. **ğŸ“Š Rich Results**: Display with rankings, costs, and publication guidelines

## ğŸ“Š Demo & Examples

### Example Results
After uploading a manuscript about machine learning in medical diagnosis, you might see:

| Journal | Similarity | Rank | APC | Access |
|---------|------------|------|-----|---------|
| **Nature Medicine** | 94.2% | #1 (Q1) | $9,750 | Hybrid |
| **The Lancet Digital Health** | 91.8% | #5 (Q1) | $5,000 | Hybrid |
| **PLOS Medicine** | 89.1% | #12 (Q1) | $3,000 | Open |

### Use Cases
- **ğŸ“ Academic Researchers**: Find the best journals for your field
- **ğŸ“š PhD Students**: Navigate journal selection for dissertations  
- **ğŸ¥ Medical Professionals**: Identify clinical publication opportunities
- **ğŸ“– Librarians**: Assist researchers with publication strategy
- **ğŸ¢ Research Institutions**: Streamline publication workflows

## ğŸ› ï¸ Technology Stack

- **ğŸ Backend**: Python 3.8+, FastAPI, Streamlit
- **ğŸ§  AI/ML**: Sentence Transformers, FAISS, PyTorch, Scikit-learn
- **ğŸ“„ Document Processing**: pdfplumber, python-docx, PyMuPDF
- **ğŸ“Š Data**: Pandas, NumPy, JSON
- **ğŸ” Search**: FAISS vector similarity search
- **ğŸŒ APIs**: DOAJ, OpenAlex integration

## ğŸ“š Documentation

| Resource | Description |
|----------|-------------|
| **[ğŸ“– User Guide](docs/user/)** | Complete installation and usage instructions |
| **[ğŸ”§ Developer Docs](docs/developer/)** | API reference and development setup |
| **[ğŸš€ Deployment Guide](docs/deployment/)** | Production deployment instructions |
| **[ğŸ“‹ Implementation Roadmap](docs/IMPLEMENTATION_ROADMAP.md)** | Future development plans |
| **[ğŸ¤– Claude Code Guide](docs/CLAUDE_CODE_DEVELOPMENT_GUIDE.md)** | Development using Claude Code |

### Quick Links
- **Installation**: [User Installation Guide](docs/user/installation-guide.md)
- **API Reference**: [Complete API Documentation](docs/api/)
- **Contributing**: [Contribution Guidelines](CONTRIBUTING.md)
- **Troubleshooting**: [Common Issues & Solutions](docs/user/troubleshooting.md)

**Key DOAJ Enhancements**:
- **Open Access Data**: `oa_status`, `in_doaj`, `oa_start_year`
- **Cost Information**: `has_apc`, `apc_amount`, `apc_currency` (supports multiple currencies)
- **Enhanced Metadata**: `subjects_doaj`, `languages`, `license_type`, `country_doaj`
- **Publisher Details**: `publisher_doaj` (often more accurate than OpenAlex data)
- **Combined Subjects**: Merges OpenAlex and DOAJ subject classifications

#### 4. Semantic Search (`match_journals.py`)
- **Input Processing**: Embed manuscript abstract using same model as journal DB
- **Search Algorithm**: FAISS cosine similarity search
- **Ranking**: Sort by similarity score with confidence thresholds
- **Filtering**: Optional metadata filters (discipline, OA status, APC range)

#### 5. Web Interface (`main.py`)
- **Framework**: Streamlit for rapid MVP development
- **Features**:
  - Drag-and-drop file upload
  - Progress indicators during processing
  - Sortable/filterable results table
  - Export functionality (CSV/PDF)
  - Direct links to journal submission pages

## Technical Stack

### Backend Dependencies
```bash
# Core framework
fastapi>=0.104.0          # API framework (alternative to Streamlit)
streamlit>=1.28.0         # Web interface for MVP

# Document processing
pdfplumber>=0.7.6         # PDF text extraction
python-docx>=0.8.11       # Word document processing
PyMuPDF>=1.23.0           # Alternative PDF processor

# Machine learning & embeddings
sentence-transformers>=2.2.2   # Embedding models
transformers>=4.35.0           # HuggingFace transformers
torch>=2.1.0                   # PyTorch backend

# Vector search & data
faiss-cpu>=1.7.4          # Vector similarity search
pandas>=2.1.0             # Data manipulation
numpy>=1.24.0             # Numerical operations

# API clients
requests>=2.31.0          # HTTP requests for APIs
sqlite3                   # Built-in database for metadata
```

### Development Tools
```bash
pytest>=7.4.0            # Testing framework
black>=23.0.0             # Code formatting
flake8>=6.0.0             # Linting
jupyter>=1.0.0            # Development notebooks
```

## Project Structure

```
manuscript-journal-matcher/
â”œâ”€â”€ README.md                     # This file
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ setup.py                      # Package configuration
â”œâ”€â”€ .gitignore                    # Git ignore patterns
â”œâ”€â”€ .env.example                  # Environment variables template
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                   # Streamlit application entry point
â”‚   â”œâ”€â”€ extractor.py              # Document metadata extraction
â”‚   â”œâ”€â”€ embedder.py               # Embedding generation and similarity
â”‚   â”œâ”€â”€ journal_db_builder.py     # Database creation and updates
â”‚   â”œâ”€â”€ match_journals.py         # Semantic matching engine
â”‚   â”œâ”€â”€ utils.py                  # Shared utilities and helpers
â”‚   â””â”€â”€ config.py                 # Configuration management
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ journal_metadata.json     # Journal information database
â”‚   â”œâ”€â”€ journal_embeddings.faiss  # Vector index for similarity search
â”‚   â”œâ”€â”€ sample_manuscripts/       # Test files for development
â”‚   â””â”€â”€ api_cache/                # Cached API responses
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_extractor.py         # Test document processing
â”‚   â”œâ”€â”€ test_embedder.py          # Test embedding functionality
â”‚   â”œâ”€â”€ test_matching.py          # Test similarity search
â”‚   â””â”€â”€ fixtures/                 # Test data files
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ build_database.py         # Initial database construction
â”‚   â”œâ”€â”€ update_journals.py        # Periodic database updates
â”‚   â””â”€â”€ benchmark_models.py       # Model performance comparison
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ api_documentation.md       # API endpoint documentation
    â”œâ”€â”€ deployment_guide.md        # Production deployment instructions
    â””â”€â”€ user_guide.md              # End-user documentation
```

## API Integration Details

### OpenAlex API
- **Endpoint**: `https://api.openalex.org/`
- **Usage**: Journal metadata, scopes, sample articles
- **Rate Limits**: 100,000 requests/day (no authentication required)
- **Key Fields**: `display_name`, `description`, `works_count`, `cited_by_count`

### DOAJ API (âœ¨ **NEW in Step 8**)
- **Endpoint**: `https://doaj.org/api/v3/`
- **Usage**: Open access status, Article Processing Charges (APC), license information, editorial policies
- **Authentication**: No API key required for basic access
- **Rate Limits**: Conservative 1 request/second (configurable)
- **Key Fields**: 
  - `bibjson.apc`: APC information including amounts and currency
  - `bibjson.oa_start`: Open access start year
  - `bibjson.subject`: Subject classifications
  - `bibjson.language`: Publication languages
  - `bibjson.license`: License types (CC BY, MIT, etc.)
  - `bibjson.publisher`: Publisher details including country
  - `bibjson.editorial`: Editorial policies and review processes
- **Integration**: Automatically enriches journal database with comprehensive open access metadata

### CrossRef API
- **Endpoint**: `https://api.crossref.org/`
- **Usage**: Publisher details, additional metadata
- **Rate Limits**: 50 requests/second (polite pool)
- **Key Fields**: `publisher`, `ISSN`, `subject`

## ğŸ¯ Implementation Status - COMPLETED âœ…

### âœ… Phase 1: MVP Development (COMPLETED)
1. **âœ… Core Infrastructure**
   - âœ… Project structure and dependencies set up
   - âœ… PDF/DOCX extraction implemented (`extractor.py`)
   - âœ… Embedding pipeline with all-MiniLM-L6-v2 (`embedder.py`)
   - âœ… Production database from Medicine Journal Rankings CSV

2. **âœ… Matching Engine**
   - âœ… FAISS vector search implemented (`match_journals.py`)
   - âœ… Cosine similarity matching with 0.005s performance
   - âœ… Full Streamlit interface with advanced filtering
   - âœ… File upload and comprehensive results display

3. **âœ… Integration & Testing**
   - âœ… CSV data integration with quality validation (96.6% success)
   - âœ… Comprehensive test suite with 10+ integration tests
   - âœ… Error handling and validation throughout system
   - âœ… Production-ready performance optimization

### âœ… Phase 2: Enhancement & Polish (COMPLETED)
- âœ… Advanced filtering: SJR quartiles, rankings, H-index, publishers
- âœ… Performance optimization: 7,648 journals, 570MB memory usage
- âœ… Enhanced UI with quality indicators and detailed metrics
- âœ… Export functionality for CSV results
- âœ… Real-time search with sub-second response times

### ğŸš€ Phase 3: Production Ready Features (IMPLEMENTED)
- âœ… Medical field specialization with 7,648 medical journals
- âœ… Quality-based ranking combining semantic similarity + journal prestige
- âœ… Advanced semantic matching understanding medical terminology
- âœ… Geographic and publisher diversity (104 countries, 2,053+ publishers)
- âœ… Comprehensive metadata integration with citation metrics

### ğŸ”® Future Enhancements (Optional)
- DOAJ integration for open access information
- Multi-language manuscript support
- Integration with journal submission systems  
- Reviewer suggestion based on references
- Fine-tuned models for specific medical subfields

## Database Construction Process

### Initial Setup
```python
# Pseudocode for database creation
def build_journal_database():
    # 1. Fetch journals from OpenAlex
    journals = fetch_openalex_journals(limit=50000)
    
    # 2. Enrich with DOAJ data
    for journal in journals:
        journal.update(fetch_doaj_info(journal.issn))
    
    # 3. Add CrossRef publisher info
    for journal in journals:
        journal.update(fetch_crossref_info(journal.issn))
    
    # 4. Create semantic fingerprints
    for journal in journals:
        fingerprint = create_semantic_fingerprint(
            scope=journal.description,
            sample_articles=fetch_sample_articles(journal.id, limit=3)
        )
        journal.semantic_fingerprint = fingerprint
    
    # 5. Generate embeddings
    embeddings = embed_texts([j.semantic_fingerprint for j in journals])
    
    # 6. Build FAISS index
    index = faiss.IndexFlatIP(embedding_dim)
    index.add(embeddings)
    
    # 7. Save to disk
    save_journal_metadata(journals)
    save_faiss_index(index)
```

## Privacy & Security

### Data Handling
- **Temporary Processing**: All uploaded files processed in memory or temporary directories
- **Automatic Cleanup**: Files deleted immediately after processing
- **No Persistent Storage**: Manuscript content never saved to disk
- **Local Processing**: Option for completely offline operation

### Security Measures
- Input validation for uploaded files
- File type verification and size limits
- Sanitization of extracted text
- Rate limiting for API calls
- Secure temporary file handling

### User Privacy
- No tracking or analytics by default
- Optional usage statistics (anonymized)
- Clear privacy policy and data handling disclosure
- GDPR compliance considerations

## Performance Considerations

### Optimization Strategies
- **Lazy Loading**: Load journal database only when needed
- **Caching**: Cache API responses and embeddings
- **Batch Processing**: Process multiple manuscripts efficiently
- **Index Optimization**: Use FAISS IVF for large databases
- **Memory Management**: Stream large files, cleanup temporary data

### Scalability
- **Horizontal Scaling**: Stateless design allows multiple instances
- **Database Sharding**: Split journal database by field/region
- **CDN Integration**: Serve static assets from CDN
- **API Rate Management**: Implement exponential backoff for external APIs

## Error Handling & Edge Cases

### Common Issues
- Malformed PDF files (use multiple extraction libraries as fallback)
- Missing abstracts (extract first paragraph or summary)
- Non-English manuscripts (add language detection)
- Very short or very long abstracts (handle edge cases gracefully)
- API rate limits (implement retry logic with exponential backoff)

### Validation
- File format verification
- Text extraction quality checks
- Embedding dimension validation
- Journal database integrity checks

## Testing Strategy

### Unit Tests
- Document extraction accuracy
- Embedding generation consistency
- Similarity calculation correctness
- API response handling

### Integration Tests
- End-to-end workflow validation
- Database construction pipeline
- External API integration
- UI functionality testing

### Performance Tests
- Large file processing
- Database query performance
- Memory usage optimization
- Concurrent user handling

## Deployment Options

### Local Development
```bash
# Setup commands
git clone [repository]
cd manuscript-journal-matcher
python -m venv venv
source venv/bin/activate  # or `venv\Scripts\activate` on Windows
pip install -r requirements.txt
python scripts/build_database.py
streamlit run src/main.py
```

### Production Deployment
- **Docker**: Containerized deployment with Docker Compose
- **Cloud Platforms**: AWS ECS, Google Cloud Run, or Heroku
- **Database**: PostgreSQL for metadata, S3/GCS for FAISS indices
- **Load Balancing**: nginx or cloud load balancer
- **Monitoring**: Application logs, performance metrics, error tracking

## Configuration

### Environment Variables
```bash
# API Keys (optional but recommended)
OPENALEX_API_KEY=your_openalex_key
DOAJ_API_KEY=your_doaj_key
CROSSREF_MAILTO=your_email@domain.com

# Application Settings
MAX_FILE_SIZE_MB=50
EMBEDDING_MODEL=all-MiniLM-L6-v2
MAX_RESULTS=20
CACHE_DURATION_HOURS=24

# Database Settings
DATABASE_PATH=data/journal_metadata.json
FAISS_INDEX_PATH=data/journal_embeddings.faiss
```

## ğŸš€ Production Usage

### Quick Start
```bash
# Clone and setup
git clone [repository]
cd manuscript-journal-matcher
python -m venv venv
source venv/bin/activate  # or `venv\Scripts\activate` on Windows
pip install -r requirements.txt

# Launch production app
streamlit run src/main.py
```

### Production API Usage
```python
# 1. Extract manuscript metadata
from src.extractor import extract_manuscript_data
title, abstract = extract_manuscript_data("manuscript.pdf")

# 2. Initialize production journal matcher
from src.match_journals import JournalMatcher
matcher = JournalMatcher()
matcher.load_database()  # Loads 7,648 journals

# 3. Search with advanced CSV-based filtering
results = matcher.search_similar_journals(
    query_text=abstract,
    top_k=10,
    filters={
        'sjr_quartiles': ['Q1', 'Q2'],   # Top 50% quality journals
        'max_rank': 500,                 # Top 500 Scimago ranked
        'min_h_index': 50,              # High impact journals
        'min_sjr_score': 1.0,           # Minimum SJR score
    }
)

# 4. Display production results with quality metrics
for match in results:
    print(f"{match['display_name']}: {match['similarity_score']:.3f}")
    print(f"  ğŸ† SJR Rank: #{match.get('scimago_rank')} ({match.get('sjr_quartile')})")
    print(f"  ğŸ“Š SJR Score: {match.get('sjr_score', 0):.2f}")
    print(f"  ğŸ“ˆ H-Index: {match.get('h_index', 0)}")
    print(f"  ğŸ¢ Publisher: {match.get('publisher')}")
    print(f"  ğŸŒ Country: {match.get('country')}")
    print()
```

### Sample Output (with DOAJ Integration)
```
PLOS Computational Biology: 0.892 ğŸ† DOAJ Listed
  Publisher: Public Library of Science
  Open Access: âœ… Yes
  APC: $1695 USD
  Languages: English
  License: CC BY

BMC Medical Imaging: 0.867 ğŸ† DOAJ Listed
  Publisher: BioMed Central
  Open Access: âœ… Yes
  APC: $2290 USD
  Languages: English
  License: CC BY

Frontiers in Neuroscience: 0.834 ğŸ† DOAJ Listed
  Publisher: Frontiers Media SA
  Open Access: âœ… Yes
  APC: $2950 USD
  Languages: English
  License: CC BY

Journal of Open Source Software: 0.812 ğŸ† DOAJ Listed
  Publisher: Open Journals
  Open Access: âœ… Yes
  APC: Free
  Languages: English
  License: MIT

Database Statistics:
ğŸ“Š Total journals: 10,247
ğŸ† DOAJ journals: 2,156 (21%)
âœ… Open Access: 3,842 (37%)
ğŸ’š Free to publish: 1,203 (12%)
ğŸ’° Average APC: $1,847 USD
```

## ğŸ† DOAJ Integration Features (Step 8)

The Manuscript Journal Matcher now includes comprehensive integration with the **Directory of Open Access Journals (DOAJ)**, providing detailed open access information and cost transparency for researchers.

### What is DOAJ?

The Directory of Open Access Journals (DOAJ) is a curated online directory that indexes and provides access to high-quality, open access, peer-reviewed journals. DOAJ helps researchers find legitimate open access journals and avoid predatory publishers.

### Enhanced Features

#### ğŸ” Advanced Filtering Options
- **Open Access Only**: Filter to show only open access journals
- **DOAJ Listed Only**: Restrict results to journals verified by DOAJ
- **APC Range Filtering**: Set maximum/minimum article processing charges
- **Free to Publish**: Find journals with no publication fees
- **Language Filtering**: Filter by publication languages
- **Enhanced Subject Matching**: Combines OpenAlex and DOAJ subject classifications

#### ğŸ’° Cost Transparency
- **Detailed APC Information**: Article Processing Charges in multiple currencies
- **Currency Support**: USD, EUR, GBP, and other major currencies
- **Free Publication Options**: Clearly marked journals with no fees
- **Cost Range Filtering**: Find journals within your budget

#### ğŸ“‹ Rich Metadata
- **License Information**: CC BY, CC BY-SA, MIT, and other license types
- **Editorial Policies**: Peer review processes and publication timelines
- **Publisher Details**: Enhanced publisher information from DOAJ
- **Geographic Information**: Journal origin countries
- **Language Support**: Multi-language publication capabilities

### Database Building with DOAJ

The enhanced database building process automatically enriches journal data:

```bash
# Build database with DOAJ integration (default)
python scripts/build_database.py --limit 1000

# Skip DOAJ integration for faster building
python scripts/build_database.py --limit 1000 --skip-doaj

# Custom DOAJ rate limiting
python scripts/build_database.py --doaj-rate-limit 0.5
```

### Filter Options Reference

| Filter Option | Type | Description | Example |
|---------------|------|-------------|---------|
| `open_access_only` | boolean | Only open access journals | `True` |
| `doaj_only` | boolean | Only DOAJ-listed journals | `True` |
| `no_apc_only` | boolean | Only free-to-publish journals | `True` |
| `max_apc` | number | Maximum APC in USD | `2000` |
| `min_apc` | number | Minimum APC in USD | `500` |
| `languages` | list | Publication languages | `['English', 'Spanish']` |
| `subjects` | list | Subject areas | `['Medicine', 'Biology']` |
| `publishers` | list | Publisher names | `['PLOS', 'BioMed Central']` |

### Streamlit Interface Enhancements

The web interface now includes:
- **Comprehensive Filter Controls**: Easy-to-use checkboxes and sliders
- **Enhanced Results Display**: DOAJ badges, APC information, license types
- **Cost Visualization**: Color-coded APC ranges and free publication indicators
- **Detailed Journal Cards**: Expandable sections with complete DOAJ metadata
- **Export with DOAJ Data**: CSV exports include all DOAJ fields

### API Response Format

Enhanced journal results now include:

```json
{
  "display_name": "PLOS Computational Biology",
  "similarity_score": 0.892,
  "publisher": "PLOS",
  "publisher_doaj": "Public Library of Science",
  "oa_status": true,
  "in_doaj": true,
  "has_apc": true,
  "apc_amount": 1695,
  "apc_currency": "USD",
  "oa_start_year": 2005,
  "subjects_doaj": ["Computational Biology", "Bioinformatics"],
  "languages": ["English"],
  "license_type": ["CC BY"],
  "country_doaj": "US"
}
```

### Testing DOAJ Integration

Comprehensive test suite includes:
- **DOAJ API Client Tests**: API response handling, rate limiting, error cases
- **Data Processing Tests**: DOAJ metadata processing and validation
- **Filtering Tests**: All DOAJ-enhanced filter options
- **Integration Tests**: End-to-end workflow with DOAJ data
- **UI Tests**: Streamlit interface with DOAJ features

Run DOAJ-specific tests:
```bash
# Run all DOAJ integration tests
pytest tests/test_doaj_integration.py -v

# Run DOAJ filtering tests
pytest tests/test_matching.py::TestDOAJEnhancedFiltering -v
```

### Performance Considerations

- **Caching**: DOAJ API responses are cached to minimize requests
- **Rate Limiting**: Conservative 1 request/second default (configurable)
- **Batch Processing**: Efficient journal enrichment in batches
- **Resume Capability**: Database building can resume from interruptions
- **Memory Optimization**: Streaming processing for large journal sets

## ğŸ¤ Contributing

We welcome contributions! Here's how to get started:

### For Users
- ğŸ› **Report Bugs**: [Create an issue](https://github.com/Cold-Mountain/manuscript-journal-matcher/issues) with details
- ğŸ’¡ **Request Features**: Share ideas for new functionality  
- ğŸ“ **Improve Docs**: Help make documentation clearer
- ğŸ§ª **Test & Feedback**: Try the system and share your experience

### For Developers
- ğŸ”§ **Fix Issues**: Check our [open issues](https://github.com/Cold-Mountain/manuscript-journal-matcher/issues)
- âš¡ **Add Features**: Implement items from our [roadmap](docs/IMPLEMENTATION_ROADMAP.md)
- ğŸ§¹ **Code Quality**: Improve performance, add tests, enhance documentation
- ğŸ¤– **Claude Code**: Use our [Claude Code guide](docs/CLAUDE_CODE_DEVELOPMENT_GUIDE.md) for development

### Quick Contribution Guide
1. **Fork** the repository
2. **Create** a feature branch: `git checkout -b feature-name`
3. **Make** your changes following our [style guide](CONTRIBUTING.md)
4. **Test** your changes: `pytest tests/`
5. **Submit** a pull request with a clear description

> **New to the project?** Check out our [Contributing Guidelines](CONTRIBUTING.md) for detailed instructions.

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

## ğŸŒŸ Acknowledgments

- **Scimago Journal Rankings** for providing comprehensive journal quality data
- **Directory of Open Access Journals (DOAJ)** for open access information
- **Sentence Transformers** community for NLP model development
- **FAISS** team for efficient similarity search capabilities
- **Streamlit** for enabling rapid web application development

---

## ğŸ“ Support & Contact

### Get Help
- ğŸ“– **Documentation**: Start with our [User Guide](docs/user/)
- ğŸ› **Issues**: [GitHub Issues](https://github.com/Cold-Mountain/manuscript-journal-matcher/issues)
- ğŸ’¬ **Discussions**: [GitHub Discussions](https://github.com/Cold-Mountain/manuscript-journal-matcher/discussions)

### Project Maintainers
- **Primary**: [@Cold-Mountain](https://github.com/Cold-Mountain)
- **Contributors**: [View all contributors](https://github.com/Cold-Mountain/manuscript-journal-matcher/graphs/contributors)

---

<div align="center">

**â­ Star this repository if it helped your research!**

[ğŸš€ Get Started](#quick-start) â€¢ [ğŸ“– Documentation](#documentation) â€¢ [ğŸ¤ Contribute](#contributing) â€¢ [ğŸ“„ License](#license)

*Built with â¤ï¸ for the research community*

</div>